# Detector de Noticias Falsas con Naive Bayes

Sistema automÃ¡tico de clasificaciÃ³n de noticias utilizando procesamiento de lenguaje natural (NLP) y el algoritmo Naive Bayes.

## ğŸ¯ Objetivo

Entrenar un modelo de Machine Learning capaz de distinguir entre noticias reales y noticias falsas analizando su contenido textual.

## ğŸ› ï¸ TecnologÃ­as

- **Python 3.x**
- **pandas**: Manejo de datos
- **scikit-learn**: Algoritmo Naive Bayes y mÃ©tricas
- **NLTK**: Procesamiento de lenguaje natural

## ğŸ“¦ InstalaciÃ³n

```bash
pip install pandas scikit-learn nltk
```

## ğŸš€ Uso

```bash
python clasificador_noticias.py
```

## ğŸ“Š Dataset

**10 noticias** etiquetadas manualmente:
- 5 noticias reales (reformas, anuncios oficiales, estudios cientÃ­ficos)
- 5 noticias falsas (afirmaciones extraordinarias, pseudociencia)

## ğŸ”§ Preprocesamiento de Texto

1. **ConversiÃ³n a minÃºsculas**
2. **EliminaciÃ³n de nÃºmeros y puntuaciÃ³n**
3. **EliminaciÃ³n de stopwords** (palabras comunes en espaÃ±ol)
4. **Stemming** (reducciÃ³n a raÃ­z de palabras)
5. **VectorizaciÃ³n TF-IDF** con unigramas y bigramas

## ğŸ§  Modelo

**Multinomial Naive Bayes** con suavizado de Laplace (alpha=0.5)

### CaracterÃ­sticas:
- VectorizaciÃ³n TF-IDF
- N-gramas (1,2) para capturar contexto
- Train/test split (70/30)

## ğŸ“ˆ MÃ©tricas

El modelo genera:
- **Accuracy** (precisiÃ³n total)
- **Matriz de confusiÃ³n**
- **PrecisiÃ³n, Recall y F1-Score** por clase
- **CaracterÃ­sticas mÃ¡s discriminantes**

## ğŸ’¡ Ejemplos de ClasificaciÃ³n

```python
nuevas_noticias = [
    "Nuevo estudio demuestra que el cafÃ© mejora la memoria",
    "Expertos afirman que los gatos pueden hablar con humanos"
]
```

**Resultados esperados:**
- Noticia 1 â†’ REAL (estudio cientÃ­fico creÃ­ble)
- Noticia 2 â†’ FAKE (afirmaciÃ³n extraordinaria)

## ğŸ“ CaracterÃ­sticas Discriminantes

El modelo identifica automÃ¡ticamente palabras y frases que son mÃ¡s comunes en:
- **Noticias reales**: gobierno, nasa, ministerio, salud
- **Noticias falsas**: milagrosa, cura, convierte, espÃ­an

## ğŸ“ Conceptos Clave

### Naive Bayes
Algoritmo probabilÃ­stico basado en el teorema de Bayes que asume independencia entre caracterÃ­sticas.

**FÃ³rmula:**
```
P(clase|texto) âˆ P(clase) Ã— âˆ P(palabra|clase)
```

### TF-IDF
TÃ©cnica de vectorizaciÃ³n que pondera palabras segÃºn:
- **TF**: Frecuencia en el documento
- **IDF**: Rareza en el corpus completo

### Stemming
ReducciÃ³n de palabras a su raÃ­z:
- "cientÃ­ficos" â†’ "cientif"
- "confirmado" â†’ "confirm"

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ clasificador_noticias.py    # CÃ³digo principal
â”œâ”€â”€ README.md                   # Este archivo
â””â”€â”€ requirements.txt            # Dependencias
```

## ğŸ” Mejoras Futuras

- [ ] Aumentar dataset de entrenamiento
- [ ] Usar embeddings pre-entrenados (Word2Vec, BERT)
- [ ] Implementar validaciÃ³n cruzada
- [ ] Crear API REST para clasificaciÃ³n en tiempo real
- [ ] Agregar anÃ¡lisis de sentimientos

## ğŸ“„ Licencia

MIT License

## âœ¨ Autor

Proyecto educativo de Machine Learning y NLP

---

â­ **Nota**: Este es un modelo de demostraciÃ³n educativa. Para uso en producciÃ³n se requiere un dataset mucho mÃ¡s grande y diverso.
